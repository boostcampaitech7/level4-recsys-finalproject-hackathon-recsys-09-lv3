{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 장치: cuda\n",
      "데이터를 로드하는 중...\n",
      "BERT 모델과 토크나이저를 로드하는 중...\n",
      "제목과 설명을 BERT로 임베딩하는 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "설명 임베딩: 100%|██████████| 37141/37141 [05:15<00:00, 117.77it/s]\n",
      "제목 임베딩: 100%|██████████| 37141/37141 [04:35<00:00, 134.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태그와 카테고리를 정수 인코딩하는 중...\n",
      "태그와 카테고리 임베딩 레이어를 초기화하는 중...\n",
      "태그와 카테고리 임베딩을 계산하는 중...\n",
      "모든 임베딩을 결합하는 중...\n",
      "최종 임베딩이 완료되었습니다!\n",
      "최종 임베딩 shape: (37141, 1632)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용할 장치: {device}\")\n",
    "\n",
    "print(\"데이터를 로드하는 중...\")\n",
    "df = pd.read_csv(\"item.csv\")\n",
    "\n",
    "def combine_text(row):\n",
    "    return f\"{row['title']} [SEP] {row['short_description']}\"\n",
    "\n",
    "print(\"제목과 설명을 하나의 텍스트로 결합하는 중...\")\n",
    "df['combined_text'] = df.apply(combine_text, axis=1)\n",
    "\n",
    "# 차원 축소를 위한 선형 레이어 추가\n",
    "class BertWithProjection(nn.Module):\n",
    "    def __init__(self, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.projection = nn.Linear(768, output_dim)  # BERT 기본 차원(768) → 사용자 정의 차원\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state.mean(dim=1)\n",
    "        return self.projection(pooled)  # 차원 축소 적용\n",
    "\n",
    "print(\"BERT 모델과 토크나이저를 로드하는 중...\")\n",
    "bert_model = BertWithProjection(output_dim=256).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embedding(text, tokenizer, model, max_length=512):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "def get_combined_embedding(text, tokenizer, model, max_length=256):\n",
    "    inputs = tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True,\n",
    "        truncation=True, \n",
    "        max_length=max_length\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding = model(**inputs)\n",
    "    return embedding.squeeze().cpu().numpy()\n",
    "\n",
    "print(\"설명+제목 텍스트 임베딩 생성 중...\")\n",
    "df['combined_embedding'] = [\n",
    "    get_combined_embedding(text, tokenizer, bert_model) \n",
    "    for text in tqdm(df['combined_text'], desc=\"설명+제목 임베딩 생성\")\n",
    "]\n",
    "\n",
    "print(\"태그와 카테고리를 정수 인코딩하는 중...\")\n",
    "tag_encoder = LabelEncoder()\n",
    "category_encoder = LabelEncoder()\n",
    "\n",
    "df['encoded_tags'] = tag_encoder.fit_transform(df['tags_sum'])\n",
    "df['encoded_categories'] = category_encoder.fit_transform(df['categories'])\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "print(\"태그와 카테고리 임베딩 레이어를 초기화하는 중...\")\n",
    "tag_embedding_layer = EmbeddingLayer(num_embeddings=len(tag_encoder.classes_), embedding_dim=64).to(device)\n",
    "category_embedding_layer = EmbeddingLayer(num_embeddings=len(category_encoder.classes_), embedding_dim=32).to(device)\n",
    "print(\"len(tag_encoder.classes_): \", len(tag_encoder.classes_))\n",
    "print(\"len(category_encoder.classes_): \", len(category_encoder.classes_))\n",
    "\n",
    "# 태그와 카테고리 임베딩 계산\n",
    "print(\"태그와 카테고리 임베딩을 계산하는 중...\")\n",
    "tag_embeddings = tag_embedding_layer(torch.tensor(df['encoded_tags'].values).to(device))\n",
    "category_embeddings = category_embedding_layer(torch.tensor(df['encoded_categories'].values).to(device))\n",
    "\n",
    "# 최종 임베딩 결합\n",
    "print(\"최종 임베딩 결합...\")\n",
    "final_features = np.concatenate([\n",
    "    np.stack(df['combined_embedding'].values),\n",
    "    tag_embeddings.detach().cpu().numpy(),\n",
    "    category_embeddings.detach().cpu().numpy()\n",
    "], axis=1)\n",
    "\n",
    "# item_id와 임베딩 매핑 생성\n",
    "print(\"item_id와 임베딩 매핑 생성...\")\n",
    "embeddings_df = pd.DataFrame({\n",
    "    'item_id': df['item_id'].values,\n",
    "    'embedding': list(final_features)\n",
    "})\n",
    "\n",
    "print(\"최종 임베딩이 완료되었습니다!\")\n",
    "print(f\"최종 임베딩 shape: {final_features.shape}\")\n",
    "print(\"\\n결과 예시:\")\n",
    "print(embeddings_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tving",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
